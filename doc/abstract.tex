\chapter{Resumen}


\chapter{Abstract}

Currently, the amount of collected data is growing. Internet companies track all
user actions in order to provide better experiences. Science experiments
generate colossal amounts of data. Another growing source of data is Internet
of Things, i.e. autonomous cars need to collect and analyze large amounts of
data in order to function properly. These, combined with the plunging cost of
data storage makes storing large amounts of information for later analysis very
compelling.

Organizations should take advantage of all these data in order to overcome
ad-hoc business decisions in favor of data-driven approaches. Therefore, to
satisfy data analysis needs, many data processing systems have appeared in
the last years. Those systems were focused on processing large amounts of
historical data. However, there is an increasing need to acquire knowledge
from data as soon as possible, allowing a prompt reaction to a wide range of
events.

This project aims to implement a distributed streaming data processing platform,
Alcaudon, allowing near real-time data analysis of unbounded data-sets. One of
the objectives of this project is to provide a powerful programming model,
making it straightforward to write distributed data analysis pipelines.
Moreover, Alcaudon has been designed contemplating scalability and
fault-tolerance. Therefore, this projects presents a robust and potent tool to
process and analyze unbounded data-sets.
